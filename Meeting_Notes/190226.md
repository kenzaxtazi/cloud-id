# Meeting Notes

## 26th February 2019

### List of actions completed

Documentation

- more documentation
- finished the poster

Model training and improvements

- Padded contextual arrays to make images
- Checked how the surface types are being used by the model
- Ran both CNN and FFN with more dropout being used, on first inspection the performance is as good as before. Haven't been able to produce graphs yet.

Decorrelation
- Take 1% of dataset and evaluate model accuracy.
- Shuffle all the values on the given input between measurements
- Evaluate accuracy of model predictions for the shuffled data
- Repeat 50 times per input

![Decorrelation](http://www.hep.ph.ic.ac.uk/~trz15/Decorrelation.png)

Decorrelation for surface flags
- Instead of shuffling, we flip the relevant bit for each input.

![InvertFlags](http://www.hep.ph.ic.ac.uk/~trz15/InvertFlags2.png)

- Realised that some of these values are perfectly correlated. 
  - Day + Twilight = 1
  - Ocean + dry_land + inland_water = 1
  - Implies that the bars for these surfaces cannot be evaluated separately
- Model evaluated with twilight removed has similar performance to previous versions
- Removal improves model simplicity / run time.


Data

- No longer using remove_night method on function



Visualisations

- Added user interface to figure to flip between masks on interactive plot
- Plotted average CALIOP agreement on polar map (see Fig. 1 and 2)

![NPole4](http://www.hep.ph.ic.ac.uk/~kt2015/NPole4.png)
Figure 1: average CALIOP agreement over North Pole (w/o NANs and anomalous pixels)

![SPole4](http://www.hep.ph.ic.ac.uk/~kt2015/SPole4.png)
Figure 2: average CALIOP agreement over South Pole (w/o NANs and anomalous pixels)


### For next week or later

- Make test functions general enough for CNN and Supermodel
- Add central pixel to star arrays